- ## 概述
	- 调用方有m个异步任务需要同时运行,只要有n(n小于等于m)个任务完成就可以随时取消其他未完成的任务,是编程中的一个常见需求,如果n=1,就类似于JavaScript中的`Promise.race函数`
	- 在写该工具函数的第一个版本时遇到了一些竞态问题,函数代码如下,该函数在并发数量小于数据量的时候,会容易出现`panic: send on closed channel`
- ## 代码
	-
	  ```go
	  // LoopConcAsync 异步并发处理切片中的每个元素并返回结果
	  //
	  // 参数说明:
	  //   - s: 需要处理的切片
	  //   - exec: 处理每个元素的函数，接收元素值并返回结果和可能的错误
	  //   - concurrency: 可选参数，控制并发数，默认为数组长度
	  //
	  // 返回值说明:
	  //   - <-chan Result[T, V]: 结果通道，包含处理结果和可能的错误
	  //   - func(): 取消函数，用于提前终止所有并发任务
	  func LoopConcAsync[T any, V any](
	  	s []T,
	  	exec func(T) (V, error),
	  	concurrency ...int,
	  ) (<-chan Result[T, V], func()) {
	  	conc := 1
	  	if len(concurrency) > 0 && concurrency[0] > 0 {
	  		conc = concurrency[0]
	  	}
	  	concCh := make(chan struct{}, conc)
	  	resultCh := make(chan Result[T, V])
	  	ctx, cancel := context.WithCancel(context.Background())
	  	var wg sync.WaitGroup
	  
	  	go func() {
	        // 主协程
	  		defer close(resultCh)
	  		for idx, item := range s {
	  			select {
	  			case <-ctx.Done():
	  				return
	  			case concCh <- struct{}{}:
	  				wg.Add(1)
	  				go func(item T, index int) {
	                    // 工作协程
	  					defer func() {
	  						<-concCh
	  						wg.Done()
	  					}()
	  					var result Result[T, V]
	  					func() {
	  						defer func() {
	  							if r := recover(); r != nil {
	  								result.Error = fmt.Errorf("panic: %v, item: %+v, index: %d", r, item, index)
	  							}
	  						}()
	  						v, err := exec(item)
	  						result = Result[T, V]{
	  							Key:    index,
	  							Item:   item,
	  							Result: v,
	  							Error:  err,
	  						}
	  					}()
	  					select {
	  					case resultCh <- result:
	  					case <-ctx.Done():
	  					}
	  				}(item, idx)
	  			}
	  		}
	  		wg.Wait()
	  	}()
	  
	  	return resultCh, cancel
	  }
	  
	  // 测试代码如下
	  func Example_loopConcAsyncWaitFirst() {
	  	var data []int
	  	for i := 1; i < 1000; i++ {
	  		data = append(data, i)
	  	}
	  
	  	processFunc := func(n int) (int, error) {
	  		delay := 1 * time.Millisecond
	  		time.Sleep(delay)
	  		return n, nil
	  	}
	  	resultCh, cancel := LoopConcAsync(data, processFunc, 100)
	  
	  	firstResult := <-resultCh
	  	fmt.Printf("cancel前协程数量: %d\n", runtime.NumGoroutine())
	  	cancel()
	  	fmt.Printf("cancel后协程数量: %d\n", runtime.NumGoroutine())
	  
	  	fmt.Printf("firstResult: %v\n", firstResult)
	  	// Output:
	  }
	  
	  ```
		-
		  ```
		  === RUN   Example_loopConcAsyncWaitFirst
		  --- FAIL: Example_loopConcAsyncWaitFirst (0.00s)
		  got:
		  cancel前协程数量: 103
		  cancel后协程数量: 103
		  firstResult: {48 49 49 <nil>}
		  want:
		  
		  panic: send on closed channel
		  
		  goroutine 105 [running]:
		  k/kslice.LoopConcAsync[...].func1.1(0x0?)
		          /Users/mtgnorton/Coding/go/src/github.com/mtgnorton/k/kslice/kslice.go:134 +0xf4
		  created by k/kslice.LoopConcAsync[...].func1 in goroutine 23
		          /Users/mtgnorton/Coding/go/src/github.com/mtgnorton/k/kslice/kslice.go:114 +0xac
		  FAIL    k/kslice        0.196s
		  
		  
		  ```
- ## go中的唤醒机制
	- 主协程和工作协程的关键点都是在和通道交互,涉及到GMP的协程调度机制,读取通道和写入通道都有可能堵塞,阻塞后,当通道的状态发生变化时,阻塞的协程会被go运行时唤醒,唤醒后根据协程是否有可用的工作线程M执行,整个过程在微妙到毫秒之间,上述代码中涉及的阻塞唤醒如下:
		- 主协程被ctx.Done唤醒: 当cancel执行时,主协程被唤醒
		- 工作协程被ctx.Done唤醒: 当工作协程完成后,如果resultCh被阻塞或关闭,cancel执行时,工作协程被唤醒
		- 主协程被concCh唤醒: 当有concCh有可用缓存时时,主协程被唤醒,随后主协程新建工作协程
	- main协程中拿到结果后立即执行cancel,主协程被谁先唤醒以及真实的执行先后顺序都是不缺定的
- ## 问题梳理
	- 该版本的代码违反了通道关闭使用的基本原则,即通道关闭方应该是发送方,但当有多个发送方时,需要其他机制来确保发送方不会向已关闭的通道发送数据
	- ### 协程数量为103分析
		- 其中3个协程分别为: main协程,go守护协程(进行gc等),LoopConcAsync任务的主协程
		- 剩余100个为工作协程(见下方分析)
	- ### LoopConcAsync的执行过程
		- 1. 100个任务并发执行
		- 2. 第一个工作协程完成,发送结果,然后执行`<-concCh`,wg.Done(),因为resultCh无缓冲,所以其他完成的工作协程会阻塞
		- 3. main协程拿到结果,调用cancel,此时主协程和所有的工作协程会同时收到cancel通知
		- 注意:
			- 当第一个工作协程执行`<-concCh`后,第101个工作协程准备执行,这也是为什么协程数量为103的原因
	- ### panic时序
		- 当主协程和其他工作协程的时序如下时,会导致向关闭的resultCh写入,造成panic
			- 主协程:
				- time 1: 主协程收到cancel通知,退出循环,执行`wg.Wait()`
				- time 4: `wg.Wait`满足条件,准备执行`defer close(resultCh)`
				- time 6:  主协程关闭resultCh
			- 已完成的99个工作协程:
				- time 2: 99个任务都已完成等待cancel通知,收到cancel通知后,陆续退出
			- 新启动的工作协程:
				- time 3: 新的工作协程将`struct{}`写入concCh,还未执行`wg.Add(1)`
				- time 5:
					- 新启动的工作协程执行到`select{}`,resultCh还没有关闭,准备写入resultCh
				- time 7:
					- 新启动的工作协程写入resultCh,panic
			- 注意:
				- time 1,time 2,time 3 之间的时序上有很大的不确定性,任意的顺序都有可能
				- 和第101个协程一样,如果time 2,time 3发生在time 1 之前在此时随着已退出的工作协程,concCh有了余量,也有可能会新启动其它的工作协程
	- 总结
		- 问题主要出在以下两个方面:
		- 当主协程接受到cancel通知时,又创建了一些新的工作协程
		- 新的工作协程执行完成后,select判断通道是否能够发送数据和实际发送数据不是原子的,当执行到两者之间时,如果通道被关闭,就会造成`panic: send on closed channel`
- ## 优化
	- 根据问题的产生原因,优化的主要方向有两点
		- 当主协程接受到cancel通知时,不要创建新的工作协程
		- 在主协程关闭resultCh通道时,其他工作协程执行点不能处于select通道判断
	- ### 第一种方案
		-
		  ```go
		  
		  func LoopConcAsync[T any, V any](
		  	s []T,
		  	exec func(T) (V, error),
		  	concurrency ...int,
		  ) (<-chan Result[T, V], func()) {
		  	conc := 1
		  	if len(concurrency) > 0 && concurrency[0] > 0 {
		  		conc = concurrency[0]
		  	}
		  
		  	concCh := make(chan struct{}, conc)
		  	resultCh := make(chan Result[T, V])
		  	ctx, cancel := context.WithCancel(context.Background())
		  	var wg sync.WaitGroup
		  
		  	var isCancel atomic.Bool // 新增
		  
		  	go func() {
		  		defer close(resultCh)
		  		for idx, item := range s {
		  			if isCancel.Load() {
		  				return
		  			}
		  			select {
		  			case concCh <- struct{}{}:
		  				wg.Add(1)
		  				go func(item T, index int) {
		  					defer func() {
		  						<-concCh
		  						wg.Done()
		  					}()
		  					var result Result[T, V]
		  					func() {
		  						defer func() {
		  							if r := recover(); r != nil {
		  								result.Error = fmt.Errorf("panic: %v, item: %+v, index: %d", r, item, index)
		  							}
		  						}()
		  
		  						v, err := exec(item)
		  						result = Result[T, V]{
		  							Key:    index,
		  							Item:   item,
		  							Result: v,
		  							Error:  err,
		  						}
		  					}()
		  					select {
		  					case resultCh <- result:
		  					case <-ctx.Done():
		  					}
		  				}(item, idx)
		  			default:
		  			}
		  		}
		  		wg.Wait()
		  	}()
		  
		  	return resultCh, func() {
		  		isCancel.Store(true)
		  		cancel()
		  	}
		  }
		  
		  ```
		- 修改后直接通过原子锁来确定是否取消运行,主协程始终处于循环中,当判断isCancel为true时,会立即退出循环,新的工作协程不会再有运行的机会
		- 注意之前的select是没有default的,现在加上default是让for获得循环的机会,否则会阻塞在`concCh <- struct{}{}`处,在下次循环前无法判断是否已经取消运行,会多启动一个工作协程
	- ### 第二种方案
		-
		  ```go
		  func LoopConcAsync[T any, V any](
		  	s []T,
		  	exec func(T) (V, error),
		  	concurrency ...int,
		  ) (<-chan Result[T, V], func()) {
		  	conc := 1
		  	if len(concurrency) > 0 && concurrency[0] > 0 {
		  		conc = concurrency[0]
		  	}
		  
		  	concCh := make(chan struct{}, conc)
		  	resultCh := make(chan Result[T, V])
		  	ctx, cancel := context.WithCancel(context.Background())
		  	var wg sync.WaitGroup
		  
		  	go func() {
		  		defer func() {
		  			time.Sleep(time.Millisecond) // 新增
		  			close(resultCh)
		  		}()
		  		for idx, item := range s {
		  			select {
		  			case <-ctx.Done():
		  				return
		  			case concCh <- struct{}{}:
		  				wg.Add(1)
		  
		  				go func(item T, index int) {
		  					defer func() {
		  						<-concCh
		  						wg.Done()
		  					}()
		  					var result Result[T, V]
		  					func() {
		  						defer func() {
		  							if r := recover(); r != nil {
		  								result.Error = fmt.Errorf("panic: %v, item: %+v, index: %d", r, item, index)
		  							}
		  						}()
		  						v, err := exec(item)
		  						result = Result[T, V]{
		  							Key:    index,
		  							Item:   item,
		  							Result: v,
		  							Error:  err,
		  						}
		  					}()
		                    	// 执行点1
		  					select { //新增
		  					case <-ctx.Done():
		  						return
		  					default:
		  					}
		  					select { // 执行点2
		  					case resultCh <- result:
		  					case <-ctx.Done():
		  					}
		  				}(item, idx)
		  			}
		  		}
		  		wg.Wait()
		  	}()
		  
		  	return resultCh, cancel
		  }
		  ```
		- 第二种方案的主要思路就是确保在主协程关闭resultCh通道时,其他新启动的工作协程执行点不能处于select通道判断处,考虑一下新启动的工作协程执行点可能处于的位置,如上方注释所示
			- 位于执行点1之前,此时使用新增的select来判断返回
			- 位于执行点2处,此时主协程通过等待1ms,来让该协程完成select判断,然后再关闭通道
- ## 总结
	- 在并发编程中,需要遵循一些基本原则,比如使用通道时不允许接收方关闭通道和,不能关闭一个有多个并发发送者的通道,当需要越过一些基本原则时,要非常小心,在编写测试用例时要考虑各种边界情况。
	- 在处理并发问题时,要特别注意竞态条件,可以通过添加日志、使用race detector等工具来帮助排查问题。
	- 对于复杂的并发场景,建议先画出时序图,分析各个协程的执行顺序和状态变化,这样可以更好地理解和解决问题。
	- 最后,在编写并发代码时要保持谨慎和耐心,多写测试用例,多考虑边界情况,这样才能写出健壮的并发程序。
